#!/bin/bash
echo "Reading config file"
. ./crawl.config
mkdir -p $OUTPUTDIR
echo "Starting crawl"
while read asin 
do
	echo "Downloading ASIN: $asin"
	curl -H "$USERAGENT" "https://www.amazon.com/product-reviews/$asin/ref=cm_cr_dp_d_show_all_top?ie=UTF8&reviewerType=all_reviews" |
 	tee $OUTPUTDIR/$asin.html |
  	scrape -b -e 'div.review > div.celwidget' |
 	xml2json |
	jq -c 'if (.html.body.div | type) == "object" then (.html.body.div) else (.html.body.div[]) end | {title: .div[0].a[1]."$t", date: .div[1].span[3]."$t", author: .div[1].span[0].a."$t", rating: .div[0].a[0].i.span."$t", body: .div[3].span."$t", asin: "'$asin'"}' |
 	tee $OUTPUTDIR/$asin.json |
	json2csv -p -k=title,date,author,rating,body,asin \
	> $OUTPUTDIR/$asin.csv
	waitperiod=$(shuf -i $WAITSTART-$WAITEND -n 1)
	echo "Sleeping for $waitperiod seconds"
	sleep $waitperiod
done < $ASINLIST
